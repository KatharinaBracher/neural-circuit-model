Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Gillett2020,
abstract = {Sequential activity has been observed in multiple neuronal circuits across species, neural structures, and behaviors. It has been hypothesized that sequences could arise from learning processes. However, it is still unclear whether biologically plausible synaptic plasticity rules can organize neuronal activity to form sequences whose statistics match experimental observations. Here, we investigate temporally asymmetric Hebbian rules in sparsely connected recurrent rate networks and develop a theory of the transient sequential activity observed after learning. These rules transform a sequence of random input patterns into synaptic weight updates. After learning, recalled sequential activity is reflected in the transient correlation of network activity with each of the stored input patterns. Using mean-field theory, we derive a low-dimensional description of the network dynamics and compute the storage capacity of these networks. Multiple temporal characteristics of the recalled sequential activity are consistent with experimental observations. We find that the degree of sparseness of the recalled sequences can be controlled by nonlinearities in the learning rule. Furthermore, sequences maintain robust decoding, but display highly labile dynamics, when synaptic connectivity is continuously modified due to noise or storage of other patterns, similar to recent observations in hippocampus and parietal cortex. Finally, we demonstrate that our results also hold in recurrent networks of spiking neurons with separate excitatory and inhibitory populations.},
author = {Gillett, Maxwell and Pereira, Ulises and Brunel, Nicolas},
doi = {10.1073/pnas.1918674117},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/gillett_brunel20_PNAS.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Hebbian plasticity,Recurrent networks,Sequences},
number = {47},
pages = {29948--29958},
pmid = {33177232},
title = {{Characteristics of sequential activity in networks with temporally asymmetric Hebbian learning}},
volume = {117},
year = {2020}
}
@article{Wang2018,
abstract = {Musicians can perform at different tempos, speakers can control the cadence of their speech, and children can flexibly vary their temporal expectations of events. To understand the neural basis of such flexibility, we recorded from the medial frontal cortex of nonhuman primates trained to produce different time intervals with different effectors. Neural responses were heterogeneous, nonlinear, and complex, and they exhibited a remarkable form of temporal invariance: firing rate profiles were temporally scaled to match the produced intervals. Recording from downstream neurons in the caudate and from thalamic neurons projecting to the medial frontal cortex indicated that this phenomenon originates within cortical networks. Recurrent neural network models trained to perform the task revealed that temporal scaling emerges from nonlinearities in the network and that the degree of scaling is controlled by the strength of external input. These findings demonstrate a simple and general mechanism for conferring temporal flexibility upon sensorimotor and cognitive functions.},
author = {Wang, Jing and Narain, Devika and Hosseini, Eghbal A. and Jazayeri, Mehrdad},
doi = {10.1038/s41593-017-0028-6},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/wang_jazayeri18_NatNeuro.pdf:pdf},
issn = {15461726},
journal = {Nature Neuroscience},
number = {1},
pages = {102--112},
pmid = {29203897},
publisher = {Springer US},
title = {{Flexible timing by temporal scaling of cortical responses}},
url = {http://dx.doi.org/10.1038/s41593-017-0028-6},
volume = {21},
year = {2018}
}
@article{Egger2020,
abstract = {Humans and animals can effortlessly coordinate their movements with external stimuli. This capacity indicates that sensory inputs can rapidly and flexibly reconfigure the ongoing dynamics in the neural circuits that control movements. Here, we develop a circuit-level model that coordinates movement times with expected and unexpected temporal events. The model consists of two interacting modules, a motor planning module that controls movement times and a sensory anticipation module that anticipates external events. Both modules harbor a reservoir of latent dynamics, and their interaction forms a control system whose output is adjusted adaptively to minimize timing errors. We show that the model's output matches human behavior in a range of tasks including time interval production, periodic production, synchronization/continuation, and Bayesian time interval reproduction. These results demonstrate how recurrent interactions in a simple and modular neural circuit could create the dynamics needed to control timing behavior.},
author = {Egger, Seth W. and Le, Nhat M. and Jazayeri, Mehrdad},
doi = {10.1038/s41467-020-16999-8},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/egger_jazayeri20_NatCom.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pages = {1--14},
pmid = {32770038},
publisher = {Springer US},
title = {{A neural circuit model for human sensorimotor timing}},
url = {http://dx.doi.org/10.1038/s41467-020-16999-8},
volume = {11},
year = {2020}
}
@article{Figure2014,
abstract = {High strength and high toughness are usually mutually exclusive in engineering materials. In ceramics, improving toughness usually relies on the introduction of a metallic or polymeric ductile phase, but this decreases the material's strength and stiffness as well as its high-temperature stability. Although natural materials that are both strong and tough rely on a combination of mechanisms operating at different length scales, the relevant structures have been extremely difficult to replicate. Here, we report a bioinspired approach based on widespread ceramic processing techniques for the fabrication of bulk ceramics without a ductile phase and with a unique combination of high strength (470 MPa), high toughness (22 MPa m 1/2), and high stiffness (290 GPa). Because only mineral constituents are needed, these ceramics retain their mechanical properties at high temperatures (600 °C). Our bioinspired, material-independent approach should find uses in the design and processing of materials for structural, transportation and energy-related applications. {\textcopyright} 2014 Macmillan Publishers Limited.},
archivePrefix = {arXiv},
arxivId = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1–7. Available at: http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164&tool=pmcentrez&rendertype=abstract.},
author = {Figure, Supplementary},
eprint = {/www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164&tool=pmcentrez&rendertype=abstract.},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/narain_jazayeri18_NatCom_Supp.pdf:pdf},
isbn = {1864985399},
issn = {14764660},
journal = {Nature Materials},
number = {5},
pages = {508--514},
pmid = {20944749},
primaryClass = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1–7. Available at: http:},
title = {{Supplementary information}},
volume = {13},
year = {2014}
}
@article{Bi2020a,
abstract = {To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How do animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multiseconds in working memory? How is temporal information processed concurrently with spatial information and decision making? Why are there strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and nontemporal information is coded in subspaces orthogonal with each other, and the state trajectories with time at different nontemporal information are quasiparallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and nontemporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of nontemporal information are similar or not. We identified four factors that facilitate strong temporal signals in nontiming tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and it is supported by and gives predictions to a number of experimental phenomena.},
archivePrefix = {arXiv},
arxivId = {1910.05546},
author = {Bi, Zedong and Zhou, Changsong},
doi = {10.1073/pnas.1921609117},
eprint = {1910.05546},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/bi_zhou20_PNAS.pdf:pdf},
isbn = {1921609117},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Interval timing,Neural network model,Population coding},
number = {19},
pages = {10530--10540},
pmid = {32341153},
title = {{Understanding the computation of time using neural network models}},
volume = {117},
year = {2020}
}
@article{Narain2018,
abstract = {Knowledge about the statistical regularities of the world is essential for cognitive and sensorimotor function. In the domain of timing, prior statistics are crucial for optimal prediction, adaptation and planning. Where and how the nervous system encodes temporal statistics is, however, not known. Based on physiological and anatomical evidence for cerebellar learning, we develop a computational model that demonstrates how the cerebellum could learn prior distributions of time intervals and support Bayesian temporal estimation. The model shows that salient features observed in human Bayesian time interval estimates can be readily captured by learning in the cerebellar cortex and circuit level computations in the cerebellar deep nuclei. We test human behavior in two cerebellar timing tasks and find prior-dependent biases in timing that are consistent with the predictions of the cerebellar model.},
author = {Narain, Devika and Remington, Evan D. and Zeeuw, Chris I.De and Jazayeri, Mehrdad},
doi = {10.1038/s41467-017-02516-x},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/narain_jazayeri18_NatCom.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pages = {1--12},
pmid = {29391392},
publisher = {Springer US},
title = {{A cerebellar mechanism for learning prior distributions of time intervals}},
url = {http://dx.doi.org/10.1038/s41467-017-02516-x},
volume = {9},
year = {2018}
}
@article{Thurley2016,
abstract = {Judgments of physical stimuli show characteristic biases; relatively small stimuli are overestimated whereas relatively large stimuli are underestimated (regression effect). Such biases likely result from a strategy that seeks to minimize errors given noisy estimates about stimuli that itself are drawn from a distribution, i.e. the statistics of the environment. While being conceptually well described, it is unclear how such a strategy could be implemented neurally. The present paper aims toward answering this question. A theoretical approach is introduced that describes magnitude estimation as two successive stages of noisy (neural) integration. Both stages are linked by a reference memory that is updated with every new stimulus. The model reproduces the behavioral characteristics of magnitude estimation and makes several experimentally testable predictions. Moreover, the model identifies the regression effect as a means of minimizing estimation errors and explains how this optimality strategy depends on the subject's discrimination abilities and on the stimulus statistics. The latter influence predicts another property of magnitude estimation, the so-called range effect. Beyond being successful in describing decision-making, the present work suggests that noisy integration may also be important in processing magnitudes.},
author = {Thurley, Kay},
doi = {10.3389/fnint.2016.00006},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/thurley16.pdf:pdf},
issn = {16625145},
journal = {Frontiers in Integrative Neuroscience},
keywords = {Drift-diffusion model,Interval timing,Magnitude estimation,Optimality,Range effect,Regression effect,Uncertainty},
number = {FEB2016},
pages = {1--11},
title = {{Magnitude estimation with noisy integrators linked by an adaptive reference}},
volume = {10},
year = {2016}
}
@article{Egger2020a,
abstract = {Humans and animals can effortlessly coordinate their movements with external stimuli. This capacity indicates that sensory inputs can rapidly and flexibly reconfigure the ongoing dynamics in the neural circuits that control movements. Here, we develop a circuit-level model that coordinates movement times with expected and unexpected temporal events. The model consists of two interacting modules, a motor planning module that controls movement times and a sensory anticipation module that anticipates external events. Both modules harbor a reservoir of latent dynamics, and their interaction forms a control system whose output is adjusted adaptively to minimize timing errors. We show that the model's output matches human behavior in a range of tasks including time interval production, periodic production, synchronization/continuation, and Bayesian time interval reproduction. These results demonstrate how recurrent interactions in a simple and modular neural circuit could create the dynamics needed to control timing behavior.},
author = {Egger, Seth W. and Le, Nhat M. and Jazayeri, Mehrdad},
doi = {10.1038/s41467-020-16999-8},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/egger_jazayeri20_NatCom_Supp.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pmid = {32770038},
title = {{A neural circuit model for human sensorimotor timing}},
volume = {11},
year = {2020}
}
@article{Bi2020,
abstract = {To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How do animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multiseconds in working memory? How is temporal information processed concurrently with spatial information and decision making? Why are there strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and nontemporal information is coded in subspaces orthogonal with each other, and the state trajectories with time at different nontemporal information are quasiparallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and nontemporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of nontemporal information are similar or not. We identified four factors that facilitate strong temporal signals in nontiming tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and it is supported by and gives predictions to a number of experimental phenomena.},
archivePrefix = {arXiv},
arxivId = {1910.05546},
author = {Bi, Zedong and Zhou, Changsong},
doi = {10.1073/pnas.1921609117},
eprint = {1910.05546},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/bi_zhou20_PNAS_Supp.pdf:pdf},
isbn = {1921609117},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Interval timing,Neural network model,Population coding},
number = {19},
pages = {10530--10540},
pmid = {32341153},
title = {{Understanding the computation of time using neural network models}},
volume = {117},
year = {2020}
}
@article{Simen2011a,
abstract = {We show that simple assumptions about neural processing lead to a model of interval timing as a temporal integration process, in which a noisy firing-rate representation of time rises linearly on average toward a response threshold over the course of an interval. Our assumptions include: that neural spike trains are approximately independent Poisson processes, that correlations among them can be largely cancelled by balancing excitation and inhibition, that neural populations can act as integrators, and that the objective of timed behavior is maximal accuracy and minimal variance. The model accounts for a variety of physiological and behavioral findings in rodents, monkeys, and humans, including ramping firing rates between the onset of reward-predicting cues and the receipt of delayed rewards, and universally scale-invariant response time distributions in interval timing tasks. It furthermore makes specific, well-supported predictions about the skewness of these distributions, a feature of timing data that is usually ignored. The model also incorporates a rapid (potentially one-shot) duration-learning procedure. Human behavioral data support the learning rule's predictions regarding learning speed in sequences of timed responses. These results suggest that simple, integration-based models should play as prominent a role in interval timing theory as they do in theories of perceptual decision making, and that a common neural mechanism may underlie both types of behavior. {\textcopyright}2011 the authors.},
author = {Simen, Patrick and Balci, Fuat and DeSouza, Laura and Cohen, Jonathan D. and Holmes, Philip},
doi = {10.1523/JNEUROSCI.3121-10.2011},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/simen_holmes11_JN.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
number = {25},
pages = {9238--9253},
pmid = {21697374},
title = {{A model of interval timing by neural integration}},
volume = {31},
year = {2011}
}
@article{Simen2011,
abstract = {We show that simple assumptions about neural processing lead to a model of interval timing as a temporal integration process, in which a noisy firing-rate representation of time rises linearly on average toward a response threshold over the course of an interval. Our assumptions include: that neural spike trains are approximately independent Poisson processes, that correlations among them can be largely cancelled by balancing excitation and inhibition, that neural populations can act as integrators, and that the objective of timed behavior is maximal accuracy and minimal variance. The model accounts for a variety of physiological and behavioral findings in rodents, monkeys, and humans, including ramping firing rates between the onset of reward-predicting cues and the receipt of delayed rewards, and universally scale-invariant response time distributions in interval timing tasks. It furthermore makes specific, well-supported predictions about the skewness of these distributions, a feature of timing data that is usually ignored. The model also incorporates a rapid (potentially one-shot) duration-learning procedure. Human behavioral data support the learning rule's predictions regarding learning speed in sequences of timed responses. These results suggest that simple, integration-based models should play as prominent a role in interval timing theory as they do in theories of perceptual decision making, and that a common neural mechanism may underlie both types of behavior. {\textcopyright}2011 the authors.},
author = {Simen, Patrick and Balci, Fuat and DeSouza, Laura and Cohen, Jonathan D. and Holmes, Philip},
doi = {10.1523/JNEUROSCI.3121-10.2011},
file = {:home/katharina/Documents/Studium/Master/thesis/paper/simen_holmes11_JN_Supp.pdf:pdf},
issn = {02706474},
journal = {Journal of Neuroscience},
number = {25},
pages = {9238--9253},
pmid = {21697374},
title = {{A model of interval timing by neural integration}},
volume = {31},
year = {2011}
}
