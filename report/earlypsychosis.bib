Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Ji2021,
abstract = {Difficulties in advancing effective patient-specific therapies for psychiatric disorders highlight a need to develop a stable neurobiologically grounded mapping between neural and symptom variation. This gap is particularly acute for psychosis-spectrum disorders (PSD). Here, in a sample of 436 PSD patients spanning several diagnoses, we derived and replicated a dimensionality-reduced symptom space across hallmark psychopathology symptoms and cognitive deficits. In turn, these symptom axes mapped onto distinct, reproducible brain maps. Critically, we found that multivariate brain-behavior mapping techniques (e.g. canonical correlation analysis) do not produce stable results with current sample sizes. However, we show that a univariate brain- behavioral space (BBS) can resolve stable individualized prediction. Finally, we show a proof-of- principle framework for relating personalized BBS metrics with molecular targets via serotonin and glutamate receptor manipulations and neural gene expression maps derived from the Allen Human Brain Atlas. Collectively, these results highlight a stable and data-driven BBS mapping across PSD, which offers an actionable path that can be iteratively optimized for personalized clinical biomarker endpoints.},
author = {Ji, Jie Lisa and Helmer, Markus and Fonteneau, Clara and Burt, Joshua B and Tamayo, Zailyn and Dem{\v{s}}ar, Jure and Adkinson, Brendan D and Savi{\'{c}}, Aleksandar and Preller, Katrin H and Moujaes, Flora and Vollenweider, Franz X and Martin, William J and Repov{\v{s}}, Grega and Murray, John D and Anticevic, Alan},
doi = {10.7554/eLife.66968},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Mapping brain behavior space
relationships along the psychosis
spectrum
.pdf:pdf;::},
issn = {2050084X},
journal = {eLife},
month = {jul},
pmid = {34313219},
publisher = {eLife Sciences Publications Ltd},
title = {{Mapping brain-behavior space relationships along the psychosis spectrum}},
volume = {10},
year = {2021}
}
@article{Phan2019,
abstract = {On April 18, 2017, the International Federation of Classification Societies (IFCS) issued a challenge to its members and the classification community to analyze a data set of 928 low back pain patients. In this paper, we present our contribution in terms of a cluster analysis of this data set. We will discuss our data cleaning process, which we view as a two-pronged approach: inferring values that are missing not at random and imputing values that are missing at random. We will also discuss the challenges in clustering mixed data types and the required data transformation prior to applying a clustering algorithm. We call our proposed data transformation process split-then-join. Finally, we offer our interpretation of the clustering results with respect to validation variables and we present some thoughts on selecting important variables to classify new observations.},
author = {Phan, Le and Liu, Hongzhe and Tortora, Cristina},
doi = {10.5445/KSP/1000085952/05},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/phan.pdf:pdf},
issn = {2510-0564},
journal = {Researchgate.Net},
number = {1},
pages = {1--17},
title = {{K-Means Clustering on Multiple Correspondence Analysis Coordinates}},
volume = {1},
year = {2019}
}
@article{Ng2001,
author = {Ng, Andrew Y. and Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
journal = {ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS },
pages = {849----856},
title = {{On Spectral Clustering: Analysis and an algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100},
volume = {14},
year = {2001}
}
@article{Anand2014,
abstract = {Factor Analysis is a very useful linear algebra technique used for dimensionality reduction. It is also used for data compression and visualization of high dimensional datasets. This technique tries to identify from among a large set of variables, a reduced set of components which summarizes the original data. This is done by identifying groups of variables which have a strong inter correlation. The original variables are transformed into a smaller set of components which have a strong linear correlation. Using several data analysis techniques like Principal Components Analysis (PCA), Factor Analysis, cluster analysis may give insight into the patterns present in the data but may also give different results. The aim of this work is to study the use of Factor Analysis (FA) in capturing the cluster structures from transportation (HIS) data. It is proposed to compare the clustering obtained from original data from that of factor scores. Steps involved in preprocessing the transportation data are also illustrated.},
author = {Anand, Sesham and Padmanabham, P and Govardhan, A},
doi = {10.5120/16673-6677},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Application of Factor Analysis to k-means Clustering
Algorithm on Transportation Data
.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {data,fa,factor analysis,high dimensional,his,house hold interview survey,pca,principal components analysis},
number = {15},
pages = {40--46},
title = {{Application of Factor Analysis to k-means Clustering Algorithm on Transportation Data}},
volume = {95},
year = {2014}
}
@article{Wagstaff2004,
abstract = {Clustering algorithms can identify groups in large data sets, such as star catalogs and hyperspectral images. In general, clustering methods cannot analyze items that have missing data values. Common solutions either fill in the missing values (imputation) or ignore the missing data (marginalization). Imputed values are treated as just as reliable as the truly observed data, but they are only as good as the assumptions used to create them. In contrast, we present a method for encoding partially observed features as a set of supplemental soft constraints and introduce the KSC algorithm, which incorporates constraints into the clustering process. In experiments on artificial data and data from the Sloan Digital Sky Survey, we show that soft constraints are an effective way to enable clustering with missing values.},
author = {Wagstaff, Kiri},
doi = {10.1007/978-3-642-17103-1_61},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/wagstaff2004.pdf:pdf},
journal = {Classification, Clustering, and Data Mining Applications},
pages = {649--658},
title = {{Clustering with Missing Values: No Imputation Required}},
year = {2004}
}
@incollection{Blasius2006,
abstract = {An appendix at the end of the book gives further computing details along with code written in the R language for performing MCA and related techniques.},
author = {Blasius, Jorg and Greenacre, Michael},
doi = {10.1201/9781420011319.ch1},
month = {jun},
pages = {3--40},
title = {{Correspondence Analysis and Related Methods in Practice}},
year = {2006}
}
@techreport{Manual2020,
address = {Indianapolis},
author = {Breier, Alan and Shenton, Martha and Holt, Daphne and Keshavan, Matcheri and {\"{O}}ng{\"{u}}r, Dost and Seidman, Larry},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/HCP-EP_Release_1.1_Manual.pdf:pdf},
institution = {Boston, MA: Brigham and Women's Hospital, Beth Israel Deaconess-Massachusetts Mental Health Center, McLean Hospital, Massachusetts General Hospital;},
number = {August},
title = {{HCP Early Psychosis 1.0 Data Release: Reference Manual 9}},
year = {2021}
}
@article{Hartigan1979,
abstract = {The K-means clustering algorithm is described indetail by Hartigan(1975). An efficient version of the algorithm is presented here.\nThe aim of the K-means algorithm is to divide M points in N dimensions into K clusters so that the within-cluster sum of squares is minimized. It is not practical to require that the solution has minimal sum of squares against all partitions except when M,N are small and K = 2. We seek instead "local" optima, solution such that no movement of a point from one cluster to another will reduce the within cluster sum of squares.},
author = {Hartigan, J. A. and Wong, M. A.},
doi = {10.2307/2346830},
issn = {00359254},
journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
keywords = {K,means clustering algorithm,transfer algorithm},
month = {mar},
number = {1},
pages = {100--108},
publisher = {JSTOR},
title = {{A K-Means Clustering Algorithm}},
url = {https://www.jstor.org/stable/10.2307/2346830?origin=crossref},
volume = {28},
year = {1979}
}
@article{Boluki2019a,
abstract = {Background: Missing values frequently arise in modern biomedical studies due to various reasons, including missing tests or complex profiling technologies for different omics measurements. Missing values can complicate the application of clustering algorithms, whose goals are to group points based on some similarity criterion. A common practice for dealing with missing values in the context of clustering is to first impute the missing values, and then apply the clustering algorithm on the completed data. Results: We consider missing values in the context of optimal clustering, which finds an optimal clustering operator with reference to an underlying random labeled point process (RLPP). We show how the missing-value problem fits neatly into the overall framework of optimal clustering by incorporating the missing value mechanism into the random labeled point process and then marginalizing out the missing-value process. In particular, we demonstrate the proposed framework for the Gaussian model with arbitrary covariance structures. Comprehensive experimental studies on both synthetic and real-world RNA-seq data show the superior performance of the proposed optimal clustering with missing values when compared to various clustering approaches. Conclusion: Optimal clustering with missing values obviates the need for imputation-based pre-processing of the data, while at the same time possessing smaller clustering errors.},
author = {Boluki, Shahin and {Zamani Dadaneh}, Siamak and Qian, Xiaoning and Dougherty, Edward R},
doi = {10.1186/s12859-019-2832-3},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Optimal clustering with missing values
.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Clustering,Missing data,Optimal design,Pattern recognition},
number = {Suppl 12},
pages = {1--10},
pmid = {31216989},
publisher = {BMC Bioinformatics},
title = {{Optimal clustering with missing values}},
url = {http://dx.doi.org/10.1186/s12859-019-2832-3},
volume = {20},
year = {2019}
}
@inproceedings{Ertoz2003,
abstract = {Finding clusters in data, especially high dimensional data, is challenging when the clusters are of widely di ering shapes, sizes, and densities, and when the data contains noise and outliers. We present a novel clustering technique that addresses these issues. Our algorithm rst nds the nearest neighbors of each data point and then rede nes the similarity between pairs of points in terms of how many nearest neighbors the two points share. Using this de nition of similarity, our algorithm identi es core points and then builds clusters around the core points. The use of a shared nearest neighbor de nition of similarity alleviates problems with varying densities and high dimensionality, while the use of core points handles problems with shape and size. While our algorithm can nd the dense" clusters that other clustering algorithms nd, it also nds clusters that these approaches overlook, i.e., clusters of low or medium density which represent relatively uniform regions surrounded" by non-uniform or higher density areas. We experimentally show that our algorithm performs better than traditional methods (e.g., K-means, DBSCAN, CURE) on a variety of data sets: KDD Cup `99 network intrusion data, NASA Earth science time series data, and two-dimensional point sets. The run-time complexity of our technique is O(n2) if the similarity matrix has to be constructed. However, we discuss a number of optimizations that allow the algorithm to handle large data sets efficiently.},
author = {Ert{\"{o}}z, Levent and Steinbach, Michael and Kumar, Vipin},
booktitle = {Proceedings},
doi = {10.1137/1.9781611972733.5},
month = {may},
pages = {47--58},
publisher = {Society for Industrial \& Applied Mathematics (SIAM)},
title = {{Finding Clusters of Different Sizes, Shapes, and Densities in Noisy, High Dimensional Data}},
url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972733.5},
year = {2003}
}
@article{Boluki2019a,
abstract = {Background: Missing values frequently arise in modern biomedical studies due to various reasons, including missing tests or complex profiling technologies for different omics measurements. Missing values can complicate the application of clustering algorithms, whose goals are to group points based on some similarity criterion. A common practice for dealing with missing values in the context of clustering is to first impute the missing values, and then apply the clustering algorithm on the completed data. Results: We consider missing values in the context of optimal clustering, which finds an optimal clustering operator with reference to an underlying random labeled point process (RLPP). We show how the missing-value problem fits neatly into the overall framework of optimal clustering by incorporating the missing value mechanism into the random labeled point process and then marginalizing out the missing-value process. In particular, we demonstrate the proposed framework for the Gaussian model with arbitrary covariance structures. Comprehensive experimental studies on both synthetic and real-world RNA-seq data show the superior performance of the proposed optimal clustering with missing values when compared to various clustering approaches. Conclusion: Optimal clustering with missing values obviates the need for imputation-based pre-processing of the data, while at the same time possessing smaller clustering errors.},
author = {Boluki, Shahin and {Zamani Dadaneh}, Siamak and Qian, Xiaoning and Dougherty, Edward R.},
doi = {10.1186/s12859-019-2832-3},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Optimal clustering with missing values
.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Clustering,Missing data,Optimal design,Pattern recognition},
number = {Suppl 12},
pages = {1--10},
pmid = {31216989},
publisher = {BMC Bioinformatics},
title = {{Optimal clustering with missing values}},
url = {http://dx.doi.org/10.1186/s12859-019-2832-3},
volume = {20},
year = {2019}
}
@article{Ji2021,
abstract = {Difficulties in advancing effective patient-specific therapies for psychiatric disorders highlight a need to develop a stable neurobiologically grounded mapping between neural and symptom variation. This gap is particularly acute for psychosis-spectrum disorders (PSD). Here, in a sample of 436 PSD patients spanning several diagnoses, we derived and replicated a dimensionality-reduced symptom space across hallmark psychopathology symptoms and cognitive deficits. In turn, these symptom axes mapped onto distinct, reproducible brain maps. Critically, we found that multivariate brain-behavior mapping techniques (e.g. canonical correlation analysis) do not produce stable results with current sample sizes. However, we show that a univariate brain- behavioral space (BBS) can resolve stable individualized prediction. Finally, we show a proof-of- principle framework for relating personalized BBS metrics with molecular targets via serotonin and glutamate receptor manipulations and neural gene expression maps derived from the Allen Human Brain Atlas. Collectively, these results highlight a stable and data-driven BBS mapping across PSD, which offers an actionable path that can be iteratively optimized for personalized clinical biomarker endpoints.},
author = {Ji, Jie Lisa and Helmer, Markus and Fonteneau, Clara and Burt, Joshua B. and Tamayo, Zailyn and Dem{\v{s}}ar, Jure and Adkinson, Brendan D. and Savi{\'{c}}, Aleksandar and Preller, Katrin H. and Moujaes, Flora and Vollenweider, Franz X. and Martin, William J. and Repov{\v{s}}, Grega and Murray, John D. and Anticevic, Alan},
doi = {10.7554/eLife.66968},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Mapping brain behavior space
relationships along the psychosis
spectrum
.pdf:pdf},
issn = {2050084X},
journal = {eLife},
month = {jul},
pmid = {34313219},
publisher = {eLife Sciences Publications Ltd},
title = {{Mapping brain-behavior space relationships along the psychosis spectrum}},
volume = {10},
year = {2021}
}
@article{Beh2004,
abstract = {Over the past few decades correspondence analysis has gained an international reputation as a powerful statistical tool for the graphical analysis of contingency tables. This popularity stems from its development and application in many European countries, especially France, and its use has spread to English speaking nations such as the United States and the United Kingdom. Its growing popularity amongst statistical practitioners, and more recently those disciplines where the role of statistics is less dominant, demonstrates the importance of the continuing research and development of the methodology. The aim of this paper is to highlight the theoretical, practical and computational issues of simple correspondence analysis and discuss its relationship with recent advances that can be used to graphically display the association in two-way categorical data.},
author = {Beh, Eric J.},
doi = {10.1111/j.1751-5823.2004.tb00236.x},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Int Statistical Rev - 2007 - Beh - Simple Correspondence Analysis A Bibliographic Review.pdf:pdf},
issn = {03067734},
journal = {International Statistical Review},
keywords = {Computing issues,Correspondence analysis family,Graphical displays,Inertia,Ordered categories,Orthogonal polynomials,Pearson ratio,Profile,Reconstitution model,Singular value decomposition,Transition formula,Two-way contingency table},
number = {2},
pages = {257--284},
title = {{Simple correspondence analysis: A bibliographic review}},
volume = {72},
year = {2004}
}
@article{Anand2014,
abstract = {Factor Analysis is a very useful linear algebra technique used for dimensionality reduction. It is also used for data compression and visualization of high dimensional datasets. This technique tries to identify from among a large set of variables, a reduced set of components which summarizes the original data. This is done by identifying groups of variables which have a strong inter correlation. The original variables are transformed into a smaller set of components which have a strong linear correlation. Using several data analysis techniques like Principal Components Analysis (PCA), Factor Analysis, cluster analysis may give insight into the patterns present in the data but may also give different results. The aim of this work is to study the use of Factor Analysis (FA) in capturing the cluster structures from transportation (HIS) data. It is proposed to compare the clustering obtained from original data from that of factor scores. Steps involved in preprocessing the transportation data are also illustrated.},
author = {Anand, Sesham and Padmanabham, P. and Govardhan, A.},
doi = {10.5120/16673-6677},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/Application of Factor Analysis to k-means Clustering
Algorithm on Transportation Data
.pdf:pdf},
journal = {International Journal of Computer Applications},
keywords = {data,fa,factor analysis,high dimensional,his,house hold interview survey,pca,principal components analysis},
number = {15},
pages = {40--46},
title = {{Application of Factor Analysis to k-means Clustering Algorithm on Transportation Data}},
volume = {95},
year = {2014}
}
@article{Bouix2017,
abstract = {Resting-state functional MRI (rfMRI) correlates activity across brain regions to identify functional connectivity networks. The Human Connectome Project (HCP) for Early Psychosis has adopted the protocol of the HCP Lifespan Project, which collects 20 min of rfMRI data. However, because it is difficult for psychotic patients to remain in the scanner for long durations, we investigate here the reliability of collecting less than 20 min of rfMRI data. Varying durations of data were taken from the full datasets of 11 subjects. Correlation matrices derived from varying amounts of data were compared using the Bhattacharyya distance, and the reliability of functional network ranks was assessed using the Friedman test. We found that correlation matrix reliability improves steeply with longer windows of data up to 11–12 min, and ≥14 min of data produces correlation matrices within the variability of those produced by 18 min of data. The reliability of network connectivity rank increases with increasing durations of data, and qualitatively similar connectivity ranks for ≥10 min of data indicates that 10 min of data can still capture robust information about network connectivities.},
author = {Boluki, Shahin and {Zamani Dadaneh}, Siamak and Qian, Xiaoning and Dougherty, Edward R. and Manual, Reference and Lewandowski, Kathryn E and Bouix, Sylvain and Ongur, Dost and Andritsos, Periklis and Tsaparas, Panayiotis and Wagstaff, Kiri and Bouix, Sylvain and Swago, Sophia and West, John D and Pasternak, Ofer and Breier, Alan and Shenton, Martha E},
doi = {10.1007/978-3-319-67159-8_13},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/andritsos2016.pdf:pdf;:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/lewandowski_2020_early-psychosis-NIH.pdf:pdf;:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/HCP-EP_Release_1.1_Manual.pdf:pdf;:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/wagstaff2004.pdf:pdf;:home/katharina/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boluki et al. - 2019 - Optimal clustering with missing values.pdf:pdf},
isbn = {9783319671581},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Acquisition time,Bhattacharyya distance,Clustering,Missing data,Optimal design,Pattern recognition,Resting state,cognition,first episode,imaging,longitudinal,psychosis,schizophrenia},
month = {jun},
number = {September},
pages = {108--115},
pmid = {31216989},
publisher = {BioMed Central Ltd.},
title = {{“Evaluating acquisition time of rfmri in the human connectome project for early psychosis. How much is enough?”}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2832-3},
volume = {10511 LNCS},
year = {2020}
}
@article{Andritsos2014,
abstract = {Software intelligent development has become one of the most important research trends in software engineering. In this paper, we put forward two key concepts — intelligent development environment (IntelliDE) and software knowledge graph — for the first time. IntelliDE is an ecosystem in which software big data are aggregated, mined and analyzed to provide intelligent assistance in the life cycle of software development. We present its architecture and discuss its key research issues and challenges. Software knowledge graph is a software knowledge representation and management framework, which plays an important role in IntelliDE. We study its concept and introduce some concrete details and examples to show how it could be constructed and leveraged. {\textcopyright} 2017, Springer Science+Business Media, LLC & Science Press, China.},
author = {Andritsos, Periklis and Tsaparas, Panayiotis},
doi = {10.1007/978-1-4899-7502-7},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/andritsos2016.pdf:pdf},
isbn = {9781489975027},
journal = {Encyclopedia of Machine Learning and Data Mining},
pages = {1--6},
title = {{Encyclopedia of Machine Learning and Data Mining}},
year = {2014}
}
@techreport{Niu2011,
abstract = {Spectral clustering is a flexible clustering methodology that is applicable to a variety of data types and has the particular virtue that it makes few assumptions on cluster shapes. It has become popular in a variety of application areas, particularly in computational vision and bioinfor-matics. The approach appears, however, to be particularly sensitive to irrelevant and noisy dimensions in the data. We thus introduce an approach that automatically learns the relevant dimensions and spectral clustering simultaneously. We pursue an augmented form of spectral clustering in which an explicit projection operator is incorporated in the relaxed optimization functional. We optimize this functional over both the projection and the spectral embedding. Experiments on simulated and real data show that this approach yields significant improvements in the performance of spectral clustering.},
author = {Niu, Donglin and Dy, Jennifer G and Jordan, Michael I},
file = {:home/katharina/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niu, Dy, Jordan - 2011 - Dimensionality Reduction for Spectral Clustering(2).pdf:pdf},
issn = {1938-7228},
month = {jun},
pages = {552--560},
publisher = {JMLR Workshop and Conference Proceedings},
title = {{Dimensionality Reduction for Spectral Clustering}},
url = {https://proceedings.mlr.press/v15/niu11a.html},
year = {2011}
}
@article{Bouix2017,
abstract = {Resting-state functional MRI (rfMRI) correlates activity across brain regions to identify functional connectivity networks. The Human Connectome Project (HCP) for Early Psychosis has adopted the protocol of the HCP Lifespan Project, which collects 20 min of rfMRI data. However, because it is difficult for psychotic patients to remain in the scanner for long durations, we investigate here the reliability of collecting less than 20 min of rfMRI data. Varying durations of data were taken from the full datasets of 11 subjects. Correlation matrices derived from varying amounts of data were compared using the Bhattacharyya distance, and the reliability of functional network ranks was assessed using the Friedman test. We found that correlation matrix reliability improves steeply with longer windows of data up to 11–12 min, and ≥14 min of data produces correlation matrices within the variability of those produced by 18 min of data. The reliability of network connectivity rank increases with increasing durations of data, and qualitatively similar connectivity ranks for ≥10 min of data indicates that 10 min of data can still capture robust information about network connectivities.},
author = {Bouix, Sylvain and Swago, Sophia and West, John D. and Pasternak, Ofer and Breier, Alan and Shenton, Martha E.},
doi = {10.1007/978-3-319-67159-8_13},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/“Evaluating Acquisition Time of rfMRI.pdf:pdf},
isbn = {9783319671581},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Acquisition time,Bhattacharyya distance,Resting state},
pages = {108--115},
title = {{“Evaluating acquisition time of rfmri in the human connectome project for early psychosis. How much is enough?”}},
volume = {10511 LNCS},
year = {2017}
}
@article{Lewandowski2020,
abstract = {Psychotic disorders are severe, debilitating, and even fatal. The development of targeted and effective interventions for psychosis depends upon on clear understanding of the timing and nature of disease progression to target processes amenable to intervention. Strong evidence suggests early and ongoing neuroprogressive changes, but timing and inflection points remain unclear and likely differ across cognitive, clinical, and brain measures. Additionally, granular evidence across modalities is particularly sparse in the “bridging years” between first episode and established illness—years that may be especially critical for improving outcomes and during which interventions may be maximally effective. Our objective is the systematic, multimodal characterization of neuroprogression through the early course of illness in a cross-diagnostic sample of patients with psychosis. We aim to (1) interrogate neurocognition, structural brain measures, and network connectivity at multiple assessments over the first eight years of illness to map neuroprogressive trajectories, and (2) examine trajectories as predictors of clinical and functional outcomes. We will recruit 192 patients with psychosis and 36 healthy controls. Assessments will occur at baseline and 8- and 16-month follow ups using clinical, cognitive, and imaging measures. We will employ an accelerated longitudinal design (ALD), which permits ascertainment of data across a longer timeframe and at more frequent intervals than would be possible in a single cohort longitudinal study. Results from this study are expected to hasten identification of actionable treatment targets that are closely associated with clinical outcomes, and identify subgroups who share common neuroprogressive trajectories toward the development of individualized treatments.},
author = {Lewandowski, Kathryn E and Bouix, Sylvain and Ongur, Dost},
doi = {10.20900/jpbs.20200002},
file = {:home/katharina/Documents/Studium/Master/earlypsychosisproject/material/lewandowski_2020_early-psychosis-NIH.pdf:pdf},
journal = {Journal of Psychiatry and Brain Science},
keywords = {cognition,first episode,imaging,longitudinal,psychosis,schizophrenia},
pages = {1--25},
title = {{Neuroprogression across the Early Course of Psychosis}},
year = {2020}
}
@article{Greenacre1984,
abstract = {Geometric concepts in multidimensional space; Simple illustrations of correspondence analysis; Theory of correspondence analysis and equivalent approaches; Multiple correspondence analysis; Correspondence analysis of ratings and preferences; Use of correspondence analysis in discriminant analysis, classification, regression and cluster analysis; Special topics; Applications of correspondence analysis.},
author = {Greenacre, M. J.},
doi = {10.2307/4399},
issn = {00218790},
journal = {The Journal of Animal Ecology},
number = {3},
pages = {1031},
publisher = {London (UK) Academic Press},
title = {{Theory and Applications of Correspondence Analysis}},
url = {https://agris.fao.org/agris-search/search.do?recordID=XF2015012920},
volume = {54},
year = {1984}
}
